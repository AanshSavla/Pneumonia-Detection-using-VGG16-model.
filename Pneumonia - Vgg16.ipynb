{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f33243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Deep Learnong Libraries, Preprocsseing, Modeling, Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D,MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers.legacy import Adam, Adamax\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f664b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/Users/aanshsavla/Desktop/Aansh/AI/ML/DataSets/chest_xray/chest_xray/train'\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "folds = os.listdir(train_data_dir)\n",
    "for fold in folds:\n",
    "    if str(fold) != '.DS_Store':\n",
    "        foldpath = os.path.join(train_data_dir,fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath,file)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "# Concatenate data paths with labels into one dataframe\n",
    "Fseries = pd.Series(filepaths,name='filepaths')\n",
    "Lseries = pd.Series(labels, name='labels')\n",
    "\n",
    "train_df = pd.concat([Fseries,Lseries],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df57ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_dir = '/Users/aanshsavla/Desktop/Aansh/AI/ML/DataSets/chest_xray/chest_xray/val'\n",
    "filepaths= []\n",
    "labels = []\n",
    "\n",
    "folds = os.listdir(val_data_dir)\n",
    "for fold in folds:\n",
    "    if str(fold) != '.DS_Store':\n",
    "        foldpath = os.path.join(val_data_dir,fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath,file)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "\n",
    "# Concatenate data paths with labels into one dataframe\n",
    "Fseries = pd.Series(filepaths, name='filepaths')\n",
    "Lseries = pd.Series(labels, name='labels')\n",
    "val_df = pd.concat([Fseries,Lseries],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8056ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 244\n",
    "img_height = 244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b9797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:59:27.804428: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-02-19 17:59:27.804451: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-02-19 17:59:27.804457: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-02-19 17:59:27.804495: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-19 17:59:27.804513: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 244, 244, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 244, 244, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 244, 244, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 122, 122, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 122, 122, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 122, 122, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 61, 61, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 61, 61, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 61, 61, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 61, 61, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 30, 30, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 30, 30, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 15, 15, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights='imagenet', \n",
    "                  include_top=False,\n",
    "                  input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Show architecture\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca7ed48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 16\n",
    "\n",
    "def extract_features(df, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 7, 7, 512))  # Must be equal to the output of the convolutional base\n",
    "    labels = np.zeros(shape=(sample_count,2))\n",
    "    # Preprocess data\n",
    "    generator = datagen.flow_from_dataframe(df,\n",
    "                                            target_size=(img_width,img_height),\n",
    "                                            x_col='filepaths',y_col='labels',\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode='categorical',\n",
    "                                            color_mode = 'rgb')\n",
    "    # Pass data through convolutional base\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        print(i * batch_size)\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a1ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:59:33.763319: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "16\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "32\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "48\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "64\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "80\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "96\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "112\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "128\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "144\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "160\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "176\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "192\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "208\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "224\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "240\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "256\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "272\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "288\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "304\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "320\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "336\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "352\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "368\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "384\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "400\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "416\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "432\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "448\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "464\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "480\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "496\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "512\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "528\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "544\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "560\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "576\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "592\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "608\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "624\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "640\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "656\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "672\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "688\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "704\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "720\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "736\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "752\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "768\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "784\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "800\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "816\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "832\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "848\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "864\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "880\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "896\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "912\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "928\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "944\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "960\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "976\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "992\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1008\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1024\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1040\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1056\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1072\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1088\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1104\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1120\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1136\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1152\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1168\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1184\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1200\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1216\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1232\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1248\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1264\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1280\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1296\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1312\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1328\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1344\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1360\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1376\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1392\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1408\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1424\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1440\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1456\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1472\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1488\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1504\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1520\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1536\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1552\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1568\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1584\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1600\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1616\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1632\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1648\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1664\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1680\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1696\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1712\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1728\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1744\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1760\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1776\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1792\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1808\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1824\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1840\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1856\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1872\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1888\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1904\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1920\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1936\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1952\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1968\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1984\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2000\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2016\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2032\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2048\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2064\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2080\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2096\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2112\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2128\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2144\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2160\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2176\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2192\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2208\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2224\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2240\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2256\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2272\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2288\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2304\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2320\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2336\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2352\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2368\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2384\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "2416\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2432\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2448\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2464\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2480\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2496\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2512\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2528\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2544\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2560\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2576\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2592\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2608\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2624\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2640\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2656\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2672\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2688\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2704\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2720\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2736\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2752\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2768\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2784\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2800\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2816\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2832\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2848\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2864\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2880\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2896\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2912\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2928\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2944\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2960\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2976\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2992\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3008\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3024\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3040\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3056\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3072\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3088\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3104\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3120\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3136\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3152\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3168\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3184\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3200\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3216\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3232\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3248\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3264\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3280\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3296\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3312\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3328\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3344\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3360\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3376\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3392\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3408\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3424\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3440\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3456\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3472\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3488\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3504\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3520\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3536\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3552\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3568\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3584\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3600\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3616\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3632\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3648\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3664\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3680\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3696\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3712\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3728\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3744\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3760\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3776\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3792\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3808\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3824\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3840\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3856\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3872\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3888\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3904\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3920\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3936\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3952\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3968\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3984\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4000\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4016\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4032\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4048\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4064\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4080\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4096\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4112\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4128\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4144\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4160\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4176\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4192\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4208\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4224\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4240\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4256\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4272\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4288\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4304\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4320\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4336\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4352\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4368\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4384\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4400\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4416\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4432\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4448\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4464\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4480\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4496\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4512\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4528\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4544\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4560\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4576\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4592\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4608\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4624\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4640\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4656\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4672\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4688\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4704\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4720\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4736\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4752\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4768\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "4800\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4816\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4832\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4848\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4864\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4880\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4896\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4912\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4928\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4944\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4960\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4976\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4992\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5008\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5024\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5040\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5056\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5072\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5088\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5104\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5120\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5136\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5152\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5168\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5184\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5200\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5216\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_df, 5216)  # Agree with our small dataset size\n",
    "validation_features, validation_labels = extract_features(val_df, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad6d1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " global_average_pooling2d (  (None, 512)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1026 (4.01 KB)\n",
      "Trainable params: 1026 (4.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=(7,7,512)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea35461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74aef07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.3526 - acc: 0.8407 - val_loss: 0.6126 - val_acc: 0.6250\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.2381 - acc: 0.9133 - val_loss: 0.7597 - val_acc: 0.6250\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.2048 - acc: 0.9287 - val_loss: 0.6091 - val_acc: 0.6875\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.1864 - acc: 0.9346 - val_loss: 0.7263 - val_acc: 0.6250\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.1729 - acc: 0.9388 - val_loss: 0.7364 - val_acc: 0.6250\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.1618 - acc: 0.9421 - val_loss: 0.7512 - val_acc: 0.6250\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.1535 - acc: 0.9465 - val_loss: 0.7855 - val_acc: 0.6250\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.1471 - acc: 0.9490 - val_loss: 0.6947 - val_acc: 0.6250\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.1410 - acc: 0.9503 - val_loss: 0.5625 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.1371 - acc: 0.9519 - val_loss: 0.6277 - val_acc: 0.6875\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train model\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    history = model.fit(train_features, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size, \n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a0061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
